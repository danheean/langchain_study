"""
- https://github.com/gilbutITbook/080413/blob/main/%EC%8B%A4%EC%8A%B5/5%EC%9E%A5/5_3_PDF_%EC%9A%94%EC%95%BD_%EC%9B%B9%EC%82%AC%EC%9D%B4%ED%8A%B8_%EB%A7%8C%EB%93%A4%EA%B8%B0.py
- run: streamlit run pdf_langchain_streamlit_pypdf_rag.py --server.port 8001
"""
import os
from dotenv import load_dotenv
load_dotenv('../envls')
from PyPDF2 import PdfReader
import streamlit as st
from langchain_text_splitters import CharacterTextSplitter
#from langchain.embeddings import HuggingFaceEmbeddings
from langchain_huggingface.embeddings import HuggingFaceEmbeddings
#from langchain import FAISS
from langchain_community.vectorstores import FAISS
#from langchain.chains.question_answering import load_qa_chain
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
#from langchain.chat_models import ChatOpenAI
from langchain_openai import ChatOpenAI
#from langchain.callbacks import get_openai_callback
from langchain_community.callbacks.manager import get_openai_callback

def process_text(text):
#CharacterTextSplitterë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í• 
    text_splitter = CharacterTextSplitter(
        separator="\n",
        chunk_size=1000,
        chunk_overlap=200,
        length_function=len
    )
    chunks = text_splitter.split_text(text)

    #ì„ë² ë”© ì²˜ë¦¬(ë²¡í„° ë³€í™˜), ì„ë² ë”©ì€ HuggingFaceEmbeddings ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
    embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')
    documents = FAISS.from_texts(chunks, embeddings)
    return documents

parser = StrOutputParser()
prompt = ChatPromptTemplate.from_template("""ë„ˆëŠ” í›Œë¥­í•œ ë¹„ì„œì´ë‹¤. ì•„ë˜ [ì§ˆë¬¸]ì— ëŒ€í•´ì„œ [ë‚´ìš©]ì•ˆì—ì„œ ë‹µë³€í•´ì¤˜
[ë‚´ìš©] ~~ ì‹œì‘ ~~

{context}

[ë‚´ìš©] ~~ ë ~~

[ì§ˆë¬¸]
{question}
""")


def main():  #streamlitì„ ì´ìš©í•œ ì›¹ì‚¬ì´íŠ¸ ìƒì„±
    st.title("ğŸ“„PDF ìš”ì•½í•˜ê¸°")
    st.divider()

    # try:
    #     os.environ["OPENAI_API_KEY"] = "sk-" #openai api í‚¤ ì…ë ¥
    # except ValueError as e:
    #     st.error(str(e))
    #     return

    pdf = st.file_uploader('PDFíŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”', type='pdf')

    if pdf is not None:
        pdf_reader = PdfReader(pdf)
        text = ""   # í…ìŠ¤íŠ¸ ë³€ìˆ˜ì— PDF ë‚´ìš©ì„ ì €ì¥
        for page in pdf_reader.pages:
            text += page.extract_text()

        documents = process_text(text)
        retriever =  documents.as_retriever(search_kwargs={"k": 3})

        query = "ì—…ë¡œë“œëœ PDF íŒŒì¼ì˜ ë‚´ìš©ì„ ì•½ 3~5ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”."  # LLMì— PDFíŒŒì¼ ìš”ì•½ ìš”ì²­

        if query:
            #docs = documents.similarity_search(query)

            model = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.1)

            #llm = ChatOpenAI(model="gpt-3.5-turbo-16k", temperature=0.1)
            #chain = load_qa_chain(llm, chain_type='stuff')

            rag_chain = (
                {'context': retriever, 'question': RunnablePassthrough()}
                | prompt
                | model
                | parser
            )

            with get_openai_callback() as cost:
                # response = chain.run(input_documents=docs, question=query)
                query = "ìš”ì•½í•´ ì£¼ì„¸ìš”"
                #response = rag_chain.invoke(question=query)
                response = rag_chain.invoke(query)
                print(cost)

            st.subheader('--ìš”ì•½ ê²°ê³¼--:')
            st.write(response)

if __name__ == '__main__':
    main()
